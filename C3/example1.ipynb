{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "MhoQ0WE77laV"
            },
            "source": [
                "##### Copyright 2018 The TensorFlow Authors. @ https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "jYysdyb-CaWM"
            },
            "source": [
                "# Classification de base : classer les images de vêtements"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "FbVhjPpzn6BM"
            },
            "source": [
                "Ce guide entraîne un modèle de réseau neuronal pour classer les images de vêtements, comme les baskets et les chemises. Ce n'est pas grave si vous ne comprenez pas tous les détails ; il s'agit d'un aperçu rapide d'un programme TensorFlow complet avec les détails expliqués au fur et à mesure.\n",
                "\n",
                "Ce guide utilise [tensorflow + keras](https://www.tensorflow.org/guide/keras), une API de haut niveau pour créer et entraîner des modèles dans TensorFlow.\n",
                "\n",
                "# Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install \"keras==2.*\" tensorflow"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Importer des bibliothèques"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "dzLKpmZICaWN"
            },
            "outputs": [],
            "source": [
                "import keras\n",
                "\n",
                "# Helper libraries\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "yR0EdgrLCaWR"
            },
            "source": [
                "## Importer l'ensemble de données Fashion MNIST"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "DLdCchMdCaWQ"
            },
            "source": [
                "Ce guide utilise l'ensemble de données [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), qui contient 70 000 images en niveaux de gris réparties en 10 catégories. Les images montrent des articles vestimentaires individuels à basse résolution (28 par 28 pixels), comme illustré ci-dessous :\n",
                "\n",
                "<table>\n",
                "  <tr><td>\n",
                "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
                "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
                "  </td></tr>\n",
                "  <tr><td align=\"center\">\n",
                "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Échantillons de Fashion-MNIST</a> (par Zalando, Licence MIT).<br/>&nbsp;\n",
                "  </td></tr>\n",
                "</table>\n",
                "\n",
                "Fashion MNIST est conçu comme un remplacement direct de l'ensemble de données classique [MNIST](http://yann.lecun.com/exdb/mnist/) — souvent utilisé comme \"Bonjour, Monde\" des programmes d'apprentissage automatique pour la vision par ordinateur. L'ensemble de données MNIST contient des images de chiffres écrits à la main (0, 1, 2, etc.) dans un format identique à celui des articles vestimentaires que vous utiliserez ici.\n",
                "\n",
                "Ce guide utilise Fashion MNIST pour sa variété et parce que c'est un problème légèrement plus difficile que le MNIST classique. Les deux ensembles de données sont relativement petits et sont utilisés pour vérifier qu'un algorithme fonctionne comme prévu. Ce sont de bons points de départ pour tester et déboguer le code.\n",
                "\n",
                "Ici, 60 000 images sont utilisées pour entraîner le réseau et 10 000 images pour évaluer la précision avec laquelle le réseau a appris à classer les images. Vous pouvez accéder directement à Fashion MNIST depuis TensorFlow. Importez et [chargez les données de Fashion MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) directement depuis TensorFlow :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "7MqDQO0KCaWS"
            },
            "outputs": [],
            "source": [
                "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "t9FDsUlxCaWW"
            },
            "source": [
                "Le chargement de l'ensemble de données renvoie quatre tableaux NumPy :\n",
                "\n",
                "* Les tableaux `train_images` et `train_labels` sont l'*ensemble d'entraînement* — les données que le modèle utilise pour apprendre.\n",
                "* Le modèle est testé par rapport à l'*ensemble de test*, les tableaux `test_images` et `test_labels`.\n",
                "\n",
                "Les images sont des tableaux NumPy de taille 28x28, avec des valeurs de pixels allant de 0 à 255. Les *étiquettes* sont un tableau d'entiers, allant de 0 à 9. Elles correspondent à la *classe* de vêtement représentée par l'image :\n",
                "\n",
                "<table>\n",
                "  <tr>\n",
                "    <th>Étiquette</th>\n",
                "    <th>Classe</th>\n",
                "  </tr>\n",
                "  <tr>\n",
                "    <td>0</td>\n",
                "    <td>Haut/T-shirt</td>\n",
                "  </tr>\n",
                "  <tr>\n",
                "    <td>1</td>\n",
                "    <td>Pantalon</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>2</td>\n",
                "    <td>Pull</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>3</td>\n",
                "    <td>Robe</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>4</td>\n",
                "    <td>Manteau</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>5</td>\n",
                "    <td>Sandale</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>6</td>\n",
                "    <td>Chemise</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>7</td>\n",
                "    <td>Basket</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>8</td>\n",
                "    <td>Sac</td>\n",
                "  </tr>\n",
                "    <tr>\n",
                "    <td>9</td>\n",
                "    <td>Bottine</td>\n",
                "  </tr>\n",
                "</table>\n",
                "\n",
                "Chaque image est associée à une seule étiquette. Comme les *noms de classe* ne sont pas inclus dans l'ensemble de données, stockez-les ici pour les utiliser ultérieurement lors du traçage des images :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "IjnLH5S2CaWx"
            },
            "outputs": [],
            "source": [
                "class_names = ['Haut/T-shirt', 'Pantalon', 'Pull', 'Robe', 'Manteau',\n",
                "               'Sandale', 'Chemise', 'Basket', 'Sac', 'Bottine']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Brm0b_KACaWX"
            },
            "source": [
                "## Explorer les données\n",
                "\n",
                "Avant d'entraîner le modèle, explorons le format de l'ensemble de données. Voici ce que nous savons : il y a 60 000 images dans l'ensemble d'entraînement, et chaque image est représentée par une grille de 28 x 28 pixels :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "zW5k_xz1CaWX"
            },
            "outputs": [],
            "source": [
                "train_images.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "cIAcvQqMCaWf"
            },
            "source": [
                "De même, il y a 60 000 étiquettes dans l'ensemble d'entraînement :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "TRFYHB2mCaWb"
            },
            "outputs": [],
            "source": [
                "len(train_labels)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "YSlYxFuRCaWk"
            },
            "source": [
                "Chaque étiquette est un entier compris entre 0 et 9 :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "XKnCTHz4CaWg"
            },
            "outputs": [],
            "source": [
                "train_labels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "TMPI88iZpO2T"
            },
            "source": [
                "Il y a 10 000 images dans l'ensemble de test (`test_images`). Encore une fois, chaque image est représentée par une grille de 28 x 28 pixels :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "2KFnYlcwCaWl"
            },
            "outputs": [],
            "source": [
                "????"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rd0A0Iu0CaWq"
            },
            "source": [
                "Et l'ensemble de test contient 10 000 étiquettes (`test_labels`) d'images :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "iJmPr5-ACaWn"
            },
            "outputs": [],
            "source": [
                "????"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "ES6uQoLKCaWr"
            },
            "source": [
                "## Prétraitement des données\n",
                "\n",
                "Les données doivent être prétraitées avant d'entraîner le réseau. Si vous examinez la première image dans l'ensemble d'entraînement, vous verrez que les valeurs des pixels se situent dans la plage de 0 à 255 :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "m4VEw8Ud9Quh"
            },
            "outputs": [],
            "source": [
                "plt.figure()\n",
                "plt.imshow(train_images[0])\n",
                "plt.colorbar()\n",
                "plt.grid(False)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Wz7l27Lz9S1P"
            },
            "source": [
                "Avant de les fournir au modèle de réseau neuronal, il est essentiel de mettre les valeurs des pixels à l'échelle dans une plage de 0 à 1. Cette étape de mise à l'échelle améliore la stabilité et l'efficacité des calculs réalisés par le réseau neuronal. En outre, elle garantit que les valeurs des pixels ont un impact uniforme sur l'entraînement du modèle, favorisant ainsi une meilleure généralisation et des performances globales améliorées.\n",
                "\n",
                "Pour réaliser cette mise à l'échelle, divisez simplement les valeurs des pixels par 255. Il est crucial que cette opération soit effectuée de la même manière sur l'ensemble d'entraînement et l'ensemble de test."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "bW5WzIPlCaWv"
            },
            "outputs": [],
            "source": [
                "train_images = train_images / 255.0\n",
                "\n",
                "test_images = test_images / 255.0"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Ee638AlnCaWz"
            },
            "source": [
                "Pour vérifier que les données sont dans le format correct et que vous êtes prêt à construire et entraîner le réseau, affichons les 25 premières images de l'*ensemble d'entraînement* et affichons le nom de classe sous chaque image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "oZTImqg_CaW1"
            },
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10,10))\n",
                "for i in range(25):\n",
                "    plt.subplot(5,5,i+1)\n",
                "    plt.xticks([])\n",
                "    plt.yticks([])\n",
                "    plt.grid(False)\n",
                "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
                "    plt.xlabel(class_names[train_labels[i]])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "59veuiEZCaW4"
            },
            "source": [
                "## Construction du modèle\n",
                "\n",
                "La construction du réseau neuronal nécessite la configuration des différentes couches du modèle, puis la compilation du modèle."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Gxg1XGm0eOBy"
            },
            "source": [
                "### Configuration des couches\n",
                "\n",
                "Le bloc de construction de base d'un réseau neuronal est la [*couche*](https://www.tensorflow.org/api_docs/python/tf/keras/layers). Les couches extraient des représentations à partir des données qui leur sont fournies. Espérons que ces représentations soient pertinentes pour le problème traité.\n",
                "\n",
                "La plupart de l'apprentissage profond consiste à chaîner ensemble des couches simples. La plupart des couches, telles que `keras.layers.Dense`, possèdent des paramètres qui sont appris pendant l'entraînement."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "9ODch-OFCaW4"
            },
            "outputs": [],
            "source": [
                "model = keras.Sequential([\n",
                "    keras.layers.Input((28, 28)),\n",
                "    keras.layers.Flatten(),\n",
                "    keras.layers.Dense(128, activation='relu'),\n",
                "    keras.layers.Dense(10),\n",
                "    keras.layers.Softmax()\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "gut8A_7rCaW6"
            },
            "source": [
                "La première couche de ce réseau, `keras.layers.Flatten`, transforme le format des images d'un tableau bidimensionnel (de 28 par 28 pixels) en un tableau unidimensionnel (de 28 * 28 = 784 pixels). Vous pouvez penser à cette couche comme un déroulement des lignes de pixels de l'image et les aligner. Cette couche n'a pas de paramètres à apprendre ; elle ne fait que reformater les données.\n",
                "\n",
                "Après que les pixels ont été aplatis, le réseau se compose d'une séquence de deux couches `keras.layers.Dense`. Ce sont des couches neuronales connectées de manière dense, ou entièrement connectées. La première couche `Dense` comporte 128 nœuds (ou neurones). La deuxième (et dernière) couche retourne un tableau de logits de longueur 10. Chaque nœud contient un score indiquant que l'image actuelle appartient à l'une des 10 classes.\n",
                "\n",
                "### Compiler le modèle\n",
                "\n",
                "Avant que le modèle ne soit prêt pour l'entraînement, il a besoin de quelques réglages supplémentaires. Ceux-ci sont ajoutés lors de l'étape de [*compilation*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) du modèle :\n",
                "\n",
                "* [*Optimiseur*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) — C'est ainsi que le modèle est mis à jour en fonction des données qu'il voit et de sa fonction de perte.\n",
                "* [*Fonction de perte*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) — Cela mesure à quel point le modèle est précis pendant l'entraînement. Vous voulez minimiser cette fonction pour \"diriger\" le modèle dans la bonne direction.\n",
                "* [*Métriques*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) — Utilisées pour surveiller les étapes d'entraînement et de test. L'exemple suivant utilise la *précision*, la fraction des images correctement classées."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Lhan11blCaW7"
            },
            "outputs": [],
            "source": [
                "model.compile(optimizer='adam',\n",
                "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
                "              metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "qKF6uW-BCaW-"
            },
            "source": [
                "## Entraîner le modèle\n",
                "\n",
                "L'entraînement du modèle de réseau neuronal nécessite les étapes suivantes :\n",
                "\n",
                "1. Fournir les données d'entraînement au modèle. Dans cet exemple, les données d'entraînement se trouvent dans les tableaux `train_images` et `train_labels`.\n",
                "2. Le modèle apprend à associer les images et les étiquettes.\n",
                "3. Vous demandez au modèle de faire des prédictions sur un ensemble de test — dans cet exemple, le tableau `test_images`.\n",
                "4. Vérifiez que les prédictions correspondent aux étiquettes du tableau `test_labels`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Z4P4zIV7E28Z"
            },
            "source": [
                "### Alimenter le modèle\n",
                "\n",
                "Pour commencer l'entraînement, appelez la méthode [`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) — ainsi nommée parce qu'elle \"ajuste\" le modèle aux données d'entraînement :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "xvwvpA64CaW_"
            },
            "outputs": [],
            "source": [
                "model.fit(train_images, train_labels, epochs=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "W3ZVOhugCaXA"
            },
            "source": [
                "Pendant que le modèle s'entraîne, les métriques de perte et de précision sont affichées. Ce modèle atteint une précision d'environ 0,91 (ou 91 %) sur les données d'entraînement."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "wCpr6DGyE28h"
            },
            "source": [
                "### Évaluer l'accuracy\n",
                "\n",
                "Ensuite, comparez les performances du modèle sur l'ensemble de données de test :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "VflXLEeECaXC"
            },
            "outputs": [],
            "source": [
                "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
                "\n",
                "print('\\nTest accuracy:', test_acc)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "yWfgsmVXCaXG"
            },
            "source": [
                "Il s'avère que la précision sur l'ensemble de données de test est un peu inférieure à la précision sur l'ensemble de données d'entraînement. Cet écart entre la précision d'entraînement et la précision de test représente *le surajustement*. Le surajustement se produit lorsqu'un modèle d'apprentissage automatique performe moins bien sur de nouvelles entrées, jamais vues auparavant, que sur les données d'entraînement. Un modèle surajusté \"mémorise\" le bruit et les détails dans l'ensemble de données d'entraînement à un point tel qu'il impacte négativement les performances du modèle sur les nouvelles données. Pour plus d'informations, consultez les liens suivants :\n",
                "* [Démontrer le surajustement](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)\n",
                "* [Stratégies pour prévenir le surajustement](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Gl91RPhdCaXI"
            },
            "outputs": [],
            "source": [
                "predictions = model.predict(test_images)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "x9Kk1voUCaXJ"
            },
            "source": [
                "Ici, le modèle a prédit l'étiquette pour chaque image dans l'ensemble de test. Jetons un coup d'œil à la première prédiction :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "3DmJEUinCaXK"
            },
            "outputs": [],
            "source": [
                "predictions[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "-hw1hgeSCaXN"
            },
            "source": [
                "Une prédiction est un tableau de 10 nombres. Ils représentent la \"confiance\" du modèle que l'image correspond à chacun des 10 différents articles vestimentaires. Vous pouvez voir quelle étiquette a la valeur de confiance la plus élevée :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "qsqenuPnCaXO"
            },
            "outputs": [],
            "source": [
                "np.argmax(predictions[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "E51yS7iCCaXO"
            },
            "source": [
                "Ainsi, le modèle est le plus confiant que cette image est une botte de cheville, ou `class_names[9]`. L'examen de l'étiquette de test montre que cette classification est correcte :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Sd7Pgsu6CaXP"
            },
            "outputs": [],
            "source": [
                "test_labels[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "ygh2yYC972ne"
            },
            "source": [
                "Définissez des fonctions pour afficher l'ensemble complet des 10 prédictions de classe."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "DvYmmrpIy6Y1"
            },
            "outputs": [],
            "source": [
                "def plot_image(i, predictions_array, true_label, img):\n",
                "  true_label, img = true_label[i], img[i]\n",
                "  plt.grid(False)\n",
                "  plt.xticks([])\n",
                "  plt.yticks([])\n",
                "\n",
                "  plt.imshow(img, cmap=plt.cm.binary)\n",
                "\n",
                "  predicted_label = np.argmax(predictions_array)\n",
                "  if predicted_label == true_label:\n",
                "    color = 'blue'\n",
                "  else:\n",
                "    color = 'red'\n",
                "\n",
                "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
                "                                100*np.max(predictions_array),\n",
                "                                class_names[true_label]),\n",
                "                                color=color)\n",
                "\n",
                "def plot_value_array(i, predictions_array, true_label):\n",
                "  true_label = true_label[i]\n",
                "  plt.grid(False)\n",
                "  plt.xticks(range(10))\n",
                "  \n",
                "  plt.yticks([])\n",
                "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
                "  plt.ylim([0, 1])\n",
                "  predicted_label = np.argmax(predictions_array)\n",
                "\n",
                "  thisplot[predicted_label].set_color('red')\n",
                "  thisplot[true_label].set_color('blue')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Zh9yABaME29S"
            },
            "source": [
                "### Vérifier les prédictions\n",
                "\n",
                "Avec le modèle entraîné, vous pouvez l'utiliser pour faire des prédictions sur certaines images."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "d4Ov9OFDMmOD"
            },
            "source": [
                "Examinons l'image 0, les prédictions et le tableau de prédictions. Les étiquettes de prédiction correctes sont en bleu et les étiquettes de prédiction incorrectes sont en rouge. Le nombre donne le pourcentage (sur 100) pour l'étiquette prédite."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "HV5jw-5HwSmO"
            },
            "outputs": [],
            "source": [
                "print(list(enumerate(class_names)))\n",
                "i = 0\n",
                "plt.figure(figsize=(6,3))\n",
                "plt.subplot(1,2,1)\n",
                "plot_image(i, predictions[i], test_labels, test_images)\n",
                "plt.subplot(1,2,2)\n",
                "plot_value_array(i, predictions[i],  test_labels)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Ko-uzOufSCSe"
            },
            "outputs": [],
            "source": [
                "print(list(enumerate(class_names)))\n",
                "i = 12\n",
                "plt.figure(figsize=(6,3))\n",
                "plt.subplot(1,2,1)\n",
                "plot_image(i, predictions[i], test_labels, test_images)\n",
                "plt.subplot(1,2,2)\n",
                "plot_value_array(i, predictions[i],  test_labels)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "kgdvGD52CaXR"
            },
            "source": [
                "Traçons plusieurs images avec leurs prédictions. Notez que le modèle peut se tromper même lorsqu'il est très confiant."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "hQlnbqaw2Qu_"
            },
            "outputs": [],
            "source": [
                "# Plot the first X test images, their predicted labels, and the true labels.\n",
                "# Color correct predictions in blue and incorrect predictions in red.\n",
                "print(list(enumerate(class_names)))\n",
                "num_rows = 5\n",
                "num_cols = 3\n",
                "num_images = num_rows*num_cols\n",
                "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
                "for i in range(num_images):\n",
                "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
                "  plot_image(i, predictions[i], test_labels, test_images)\n",
                "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
                "  plot_value_array(i, predictions[i], test_labels)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "R32zteKHCaXT"
            },
            "source": [
                "## Utiliser le modèle entraîné\n",
                "\n",
                "Enfin, utilisez le modèle entraîné pour faire une prédiction sur une seule image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "yRJ7JU7JCaXT"
            },
            "outputs": [],
            "source": [
                "# Grab an image from the test dataset.\n",
                "img = test_images[1]\n",
                "\n",
                "print(img.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "vz3bVp21CaXV"
            },
            "source": [
                "Les modèles `keras` sont optimisés pour effectuer des prédictions sur un *lot* ou une collection d'exemples à la fois. Par conséquent, même si vous utilisez une seule image, vous devez l'ajouter à une liste :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "lDFh5yF_CaXW"
            },
            "outputs": [],
            "source": [
                "# Add the image to a batch where it's the only member.\n",
                "img = (np.expand_dims(img,0))\n",
                "\n",
                "print(img.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "EQ5wLTkcCaXY"
            },
            "source": [
                "Maintenant, prédisez l'étiquette correcte pour cette image :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "o_rzNSdrCaXY"
            },
            "outputs": [],
            "source": [
                "predictions_single = model.predict(img)\n",
                "\n",
                "print(predictions_single)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6Ai-cpLjO-3A"
            },
            "outputs": [],
            "source": [
                "plot_value_array(1, predictions_single[0], test_labels)\n",
                "_ = plt.xticks(range(10), class_names, rotation=45)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "cU1Y2OAMCaXb"
            },
            "source": [
                "`keras.Model.predict` retourne une liste de listes, une liste pour chaque image dans le lot de données. Obtenez les prédictions pour notre (seule) image dans le lot :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "2tRmdq_8CaXb"
            },
            "outputs": [],
            "source": [
                "np.argmax(predictions_single[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "YFc2HbEVCaXd"
            },
            "source": [
                "Et le modèle prédit une étiquette comme prévu.\n",
                "\n",
                "Pour en savoir plus sur la construction de modèles avec Keras, consultez les [guides Keras](https://www.tensorflow.org/guide/keras).\n",
                "\n",
                "\n",
                "\n",
                "## Exercice\n",
                "\n",
                "Utilisez le modèle entraîné pour les images numéro 10, 200, 1000, et votre numéro de chance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "????"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Calculer recall et precision"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "????"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "name": "classification.ipynb",
            "toc_visible": true
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
